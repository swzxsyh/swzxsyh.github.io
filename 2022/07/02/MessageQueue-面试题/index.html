<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"swzxsyh.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="为什么使用MQ 解耦 异步 削峰  MQ选型Kafka：追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务，大型公司建议可以选用，如果有日志采集功能，肯定是首选 Kafka。 RocketMQ：天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。 RocketMQ 在稳定">
<meta property="og:type" content="article">
<meta property="og:title" content="MessageQueue-面试题">
<meta property="og:url" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="swzxsyh">
<meta property="og:description" content="为什么使用MQ 解耦 异步 削峰  MQ选型Kafka：追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务，大型公司建议可以选用，如果有日志采集功能，肯定是首选 Kafka。 RocketMQ：天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。 RocketMQ 在稳定">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/28r5mhz90v.png">
<meta property="og:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/o8vnpl786j.png">
<meta property="og:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/%E4%B8%80%E8%87%B4%E6%80%A7.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c1f27036-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c211aae6-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c232a7fa-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2536ce2-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2844f10-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2a15132-7dc5-11ec-8893-fa163eb4f6be.png">
<meta property="og:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/RocketMQ.jpg">
<meta property="og:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/RocketMQ_Transaction.jpg">
<meta property="article:published_time" content="2022-07-02T10:05:01.000Z">
<meta property="article:modified_time" content="2022-08-12T20:38:15.544Z">
<meta property="article:author" content="swzxsyh">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/28r5mhz90v.png">

<link rel="canonical" href="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>MessageQueue-面试题 | swzxsyh</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="swzxsyh" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">swzxsyh</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">--笔记</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://swzxsyh.github.io/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="swzxsyh">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="swzxsyh">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MessageQueue-面试题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-07-02 18:05:01" itemprop="dateCreated datePublished" datetime="2022-07-02T18:05:01+08:00">2022-07-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-13 04:38:15" itemprop="dateModified" datetime="2022-08-13T04:38:15+08:00">2022-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="为什么使用MQ"><a href="#为什么使用MQ" class="headerlink" title="为什么使用MQ"></a>为什么使用MQ</h2><ul>
<li>解耦</li>
<li>异步</li>
<li>削峰</li>
</ul>
<h2 id="MQ选型"><a href="#MQ选型" class="headerlink" title="MQ选型"></a>MQ选型</h2><p><strong>Kafka：</strong>追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务，大型公司建议可以选用，如果有日志采集功能，肯定是首选 Kafka。</p>
<p><strong>RocketMQ：</strong>天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。</p>
<p>RocketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。</p>
<p><strong>RabbitMQ：</strong>结合 erlang 语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护，不过 RabbitMQ 的社区十分活跃，可以解决开发过程中遇到的 bug。如果你的数据量没有那么大，小公司优先选择功能比较完备的 RabbitMQ。</p>
<p><strong>ActiveMQ：</strong>官方社区现在对 ActiveMQ 5.x 维护越来越少，较少在大规模吞吐的场景中使用。</p>
<span id="more"></span>

<h2 id="Kafka-会不会丢消息"><a href="#Kafka-会不会丢消息" class="headerlink" title="Kafka 会不会丢消息"></a>Kafka 会不会丢消息</h2><p>消息丢失会发生在Broker，Producer和Consumer三种</p>
<h3 id="Producer丢失消息的情况"><a href="#Producer丢失消息的情况" class="headerlink" title="Producer丢失消息的情况"></a>Producer丢失消息的情况</h3><h4 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h4><ul>
<li><p>生产者(Producer) 调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。</p>
</li>
<li><p>为了提升效率，减少IO，producer在发送数据时可以将多个请求进行合并后发送。被合并的请求咋发送一线缓存在本地buffer中。</p>
<p>一旦producer被非法的停止了，那么buffer中的数据将丢失，broker将无法收到该部分数据。又或者，当Producer客户端内存不够时，如果采取的策略是丢弃消息（另一种策略是block阻塞），消息也会被丢失。抑或，消息产生（异步产生）过快，导致挂起线程过多，内存不足，导致程序崩溃，消息丢失。</p>
</li>
</ul>
<h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><ul>
<li>为了确定消息是发送成功，我们要判断消息发送的结果。可以采用为其添加回调函数的形式</li>
<li>为 Producer 的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3</li>
<li>异步发送消息改为同步发送消。或者service产生消息时，使用阻塞的线程池，并且线程数有一定上限。整体思路是控制消息产生速度。</li>
<li>扩大Buffer的容量配置。这种方式可以缓解该情况的出现，但不能杜绝。</li>
<li>service不直接将消息发送到buffer（内存），而是将消息写到本地的磁盘中（数据库或者文件），由另一个（或少量）生产线程进行消息发送。相当于是在buffer和service之间又加了一层空间更加富裕的缓冲层。</li>
</ul>
<h3 id="Consumer丢失消息的情况"><a href="#Consumer丢失消息的情况" class="headerlink" title="Consumer丢失消息的情况"></a>Consumer丢失消息的情况</h3><p>Consumer消费消息有下面几个步骤：</p>
<ul>
<li>接收消息</li>
<li>处理消息</li>
<li>反馈“处理完毕”（commited）</li>
</ul>
<p>Consumer的消费方式主要分为两种：</p>
<ul>
<li>自动提交offset，Automatic Offset Committing</li>
<li>手动提交offset，Manual Offset Control</li>
</ul>
<h4 id="产生原因-1"><a href="#产生原因-1" class="headerlink" title="产生原因"></a>产生原因</h4><p>Consumer自动提交的机制是根据一定的时间间隔，将收到的消息进行commit。commit过程和消费消息的过程是异步的。也就是说，可能存在消费过程未成功（比如抛出异常），commit消息已经提交了。此时消息就丢失了。</p>
<h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>手动关闭闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset </p>
<h3 id="Broker丢失消息的情况"><a href="#Broker丢失消息的情况" class="headerlink" title="Broker丢失消息的情况"></a>Broker丢失消息的情况</h3><p>Broker丢失消息是由于Kafka本身的原因造成的，kafka为了得到更高的性能和吞吐量，将数据异步批量的存储在磁盘中。消息的刷盘过程，为了提高性能，减少刷盘次数，kafka采用了批量刷盘的做法。即，按照一定的消息量，和时间间隔进行刷盘。这种机制也是由于linux操作系统决定的。将<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cdcs?from=10680">数据存储</a>到linux操作系统种，会先存储到页缓存（Page cache）中，按照时间或者其他条件进行刷盘（从page cache到file），或者通过fsync命令强制刷盘。数据在page cache中时，如果系统挂掉，数据会丢失。</p>
<p><img src="/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/28r5mhz90v.png"></p>
<p>Broker在linux服务器上高速读写以及同步到Replica</p>
<p>上图简述了broker写数据以及同步的一个过程。broker写数据只写到PageCache中，而pageCache位于内存。这部分数据在断电后是会丢失的。pageCache的数据通过linux的flusher程序进行刷盘。刷盘触发条件有三：</p>
<ul>
<li>主动调用sync或fsync函数</li>
<li>可用内存低于阀值</li>
<li>dirty data时间达到阀值。dirty是pagecache的一个标识位，当有数据写入到pageCache时，pagecache被标注为dirty，数据刷盘以后，dirty标志清除。</li>
</ul>
<p>Broker配置刷盘机制，是通过调用fsync函数接管了刷盘动作。从单个Broker来看，pageCache的数据会丢失。</p>
<p>理论上，要完全让kafka保证单个broker不丢失消息是做不到的，只能通过调整刷盘机制的参数缓解该情况。比如，减少刷盘间隔，减少刷盘数据量大小。时间越短，性能越差，可靠性越好（尽可能可靠）。这是一个选择题。</p>
<p>为了解决该问题，kafka通过producer和broker协同处理单个broker丢失参数的情况。一旦producer发现broker消息丢失，即可自动进行retry。除非retry次数超过阀值（可配置），消息才会丢失。此时需要生产者客户端手动处理该情况。那么producer是如何检测到数据丢失的呢？是通过ack机制，类似于http的三次握手的方式。</p>
<ul>
<li>acks&#x3D;0，producer不等待broker的响应，效率最高，但是消息很可能会丢。</li>
<li>acks&#x3D;1，leader broker收到消息后，不等待其他follower的响应，即返回ack。也可以理解为ack数为1。此时，如果follower还没有收到leader同步的消息leader就挂了，那么消息会丢失。按照上图中的例子，如果leader收到消息，成功写入PageCache后，会返回ack，此时producer认为消息发送成功。但此时，按照上图，数据还没有被同步到follower。如果此时leader断电，数据会丢失。</li>
<li>acks&#x3D;-1，leader broker收到消息后，挂起，等待所有ISR列表中的follower返回结果后，再返回ack。-1等效与all。这种配置下，只有leader写入数据到pagecache是不会返回ack的，还需要所有的ISR返回“成功”才会触发ack。如果此时断电，producer可以知道消息没有被发送成功，将会重新发送。如果在follower收到数据以后，成功返回ack，leader断电，数据将存在于原来的follower中。在重新选举以后，新的leader会持有该部分数据。数据从leader同步到follower，需要2步：</li>
<li><ul>
<li>数据从pageCache被刷盘到disk。因为只有disk中的数据才能被同步到replica。</li>
<li>数据同步到replica，并且replica成功将数据写入PageCache。在producer得到ack后，哪怕是所有机器都停电，数据也至少会存在于leader的磁盘内。</li>
</ul>
</li>
</ul>
<p>上面第三点提到了ISR的列表的follower，需要配合另一个参数才能更好的保证ack的有效性。ISR是Broker维护的一个“可靠的follower列表”，in-sync Replica列表，broker的配置包含一个参数：min.insync.replicas。该参数表示ISR中最少的副本数。如果不设置该值，ISR中的follower列表可能为空。此时相当于acks&#x3D;1。</p>
<p><img src="/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/o8vnpl786j.png"></p>
<p>如上图中：</p>
<ul>
<li>acks&#x3D;0，总耗时f(t) &#x3D; f(1)。</li>
<li>acks&#x3D;1，总耗时f(t) &#x3D; f(1) + f(2)。</li>
<li>acks&#x3D;-1，总耗时f(t) &#x3D; f(1) + max( f(A) , f(B) ) + f(2)。</li>
</ul>
<p>性能依次递减，可靠性依次升高。</p>
<h2 id="重复消费"><a href="#重复消费" class="headerlink" title="重复消费"></a>重复消费</h2><h3 id="产生原因："><a href="#产生原因：" class="headerlink" title="产生原因："></a>产生原因：</h3><p><strong>已经消费了数据，但是offset没有成功提交。其中很大一部分原因在于发生了再均衡。</strong></p>
<ul>
<li>消费者宕机、重启等。导致消息已经消费但是没有提交offset。</li>
<li>消费者使用自动提交offset，但当还没有提交的时候，有新的消费者加入或者移除，发生了rebalance。再次消费的时候，消费者会根据提交的偏移量来，于是重复消费了数据。</li>
<li>消息处理耗时，或者消费者拉取的消息量太多，处理耗时，超过了max.poll.interval.ms的配置时间，导致认为当前消费者已经死掉，触发再均衡。</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul>
<li>乐观锁：每个数据都有一个版本号，和当前版本号相同时进行更新操作</li>
<li>去重表（缓存）：唯一索引，如果已存在值，就不进行更新了</li>
</ul>
<h2 id="Kafka-consumer-是推还是拉？"><a href="#Kafka-consumer-是推还是拉？" class="headerlink" title="Kafka consumer 是推还是拉？"></a>Kafka consumer 是推还是拉？</h2><p>customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从broker 拉取消息。</p>
<h2 id="Kafka-的设计架构"><a href="#Kafka-的设计架构" class="headerlink" title="Kafka 的设计架构"></a>Kafka 的设计架构</h2><ul>
<li>Producer</li>
<li>Consumer</li>
<li>Topic</li>
<li>Consumer Group</li>
<li>Broker </li>
<li>Partition</li>
<li>Offset</li>
</ul>
<h2 id="Kafka-分区的目的"><a href="#Kafka-分区的目的" class="headerlink" title="Kafka 分区的目的"></a>Kafka 分区的目的</h2><p>实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。</p>
<h2 id="Kafka-是如何做到消息的有序性"><a href="#Kafka-是如何做到消息的有序性" class="headerlink" title="Kafka 是如何做到消息的有序性"></a>Kafka 是如何做到消息的有序性</h2><p>kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。</p>
<h2 id="ISR、OSR、AR-是什么"><a href="#ISR、OSR、AR-是什么" class="headerlink" title="ISR、OSR、AR 是什么"></a>ISR、OSR、AR 是什么</h2><p>ISR：In-Sync Replicas 副本同步队列<br>OSR：Out-of-Sync Replicas<br>AR：Assigned Replicas 所有副本</p>
<p>ISR是由leader维护，follower从leader同步数据有一些延迟（具体可以参见 图文了解 Kafka 的副本复制机制），超过相应的阈值会把 follower 剔除出 ISR, 存入OSR（Out-of-Sync Replicas ）列表，新加入的follower也会先存放在OSR中。AR&#x3D;ISR+OSR。</p>
<h2 id="Kafka-数据一致性原理"><a href="#Kafka-数据一致性原理" class="headerlink" title="Kafka 数据一致性原理"></a>Kafka 数据一致性原理</h2><p>一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</p>
<p><img src="/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/%E4%B8%80%E8%87%B4%E6%80%A7.png"></p>
<p>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。</p>
<p>这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</p>
<p>当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。</p>
<h2 id="Kafka-消费者是否可以消费指定分区消息"><a href="#Kafka-消费者是否可以消费指定分区消息" class="headerlink" title="Kafka 消费者是否可以消费指定分区消息"></a>Kafka 消费者是否可以消费指定分区消息</h2><p>Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的</p>
<h2 id="Kafka-的再均衡"><a href="#Kafka-的再均衡" class="headerlink" title="Kafka 的再均衡"></a>Kafka 的再均衡</h2><p>在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：<br>第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。<br>第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。<br>所以对于Rebalance来说，Coordinator起着至关重要的作用</p>
<h2 id="kafka-维护消费状态跟踪的方法有什么"><a href="#kafka-维护消费状态跟踪的方法有什么" class="headerlink" title="kafka 维护消费状态跟踪的方法有什么"></a>kafka 维护消费状态跟踪的方法有什么</h2><p>Kafka 采用了不同的策略。Topic 被分成了若干分区，每个分区在同一时间只被一个 consumer 消费。这意味着每个分区被消费的消息在日志中的位置仅仅是一个简单的整数：offset。这样就很容易标记每个分区消费状态就很容易了，仅仅需要一个整数而已。这样消费状态的跟踪就很简单了。</p>
<p>这带来了另外一个好处：consumer 可以把 offset 调成一个较老的值，去重新消费老的消息。</p>
<h2 id="Kafka主从同步"><a href="#Kafka主从同步" class="headerlink" title="Kafka主从同步"></a>Kafka主从同步</h2><p>Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topic配置副本的数量。Kafka会自动在每个个副本上备份数据，所以当一个节点down掉时数据依然是可用的。</p>
<p>Kafka的副本功能不是必须的，你可以配置只有一个副本，这样其实就相当于只有一份数据。</p>
<h2 id="Zookeeper-对于-Kafka-的作用是什么"><a href="#Zookeeper-对于-Kafka-的作用是什么" class="headerlink" title="Zookeeper 对于 Kafka 的作用是什么"></a>Zookeeper 对于 Kafka 的作用是什么</h2><p>Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用。</p>
<p>Zookeeper 主要用于在集群中不同节点之间进行通信</p>
<p>在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取除此之外，它还执行其他活动，如: leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。</p>
<h2 id="Kafka数据传输的事务定义有哪三种"><a href="#Kafka数据传输的事务定义有哪三种" class="headerlink" title="Kafka数据传输的事务定义有哪三种"></a>Kafka数据传输的事务定义有哪三种</h2><p>和 MQTT 的事务定义一样都是 3 种。</p>
<p>（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输</p>
<p>（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</p>
<p>（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的</p>
<h2 id="Kafka-判断一个节点是否还存活条件"><a href="#Kafka-判断一个节点是否还存活条件" class="headerlink" title="Kafka 判断一个节点是否还存活条件"></a>Kafka 判断一个节点是否还存活条件</h2><p>（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接</p>
<p>（2）如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久</p>
<h2 id="Kafka-与传统-MQ-消息系统之间有什么区别"><a href="#Kafka-与传统-MQ-消息系统之间有什么区别" class="headerlink" title="Kafka 与传统 MQ 消息系统之间有什么区别"></a>Kafka 与传统 MQ 消息系统之间有什么区别</h2><p>(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留</p>
<p>(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性</p>
<p>(3).Kafka 支持实时的流式处理</p>
<h2 id="消费者故障，出现活锁问题如何解决"><a href="#消费者故障，出现活锁问题如何解决" class="headerlink" title="消费者故障，出现活锁问题如何解决"></a>消费者故障，出现活锁问题如何解决</h2><p>出现“活锁”的情况，是它持续的发送心跳，但是没有处理。为了预防消费者在这种情况下一直持有分区，我们使用 max.poll.interval.ms 活跃检测机制。 在此基础上，如果你调用的 poll 的频率大于最大间隔，则客户端将主动地离开组，以便其他消费者接管该分区。 发生这种情况时，你会看到 offset 提交失败。这是一种安全机制，保障只有活动成员能够提交 offset。所以要留在组中，你必须持续调用 poll。</p>
<h2 id="Kafka如何控制消费的位置"><a href="#Kafka如何控制消费的位置" class="headerlink" title="Kafka如何控制消费的位置"></a>Kafka如何控制消费的位置</h2><p>kafka 使用 seek(TopicPartition, long)指定新的消费位置。用于查找服务器保留的最早和最新的 offset 的特殊的方法也可用（seekToBeginning(Collection) 和seekToEnd(Collection)）</p>
<h2 id="Kafka-的高可用机制是什么"><a href="#Kafka-的高可用机制是什么" class="headerlink" title="Kafka 的高可用机制是什么"></a>Kafka 的高可用机制是什么</h2><p>多副本冗余的高可用机制 </p>
<p>producer、broker 和 consumer 都会拥有多个</p>
<p>分区选举机制 、 消息确认机制</p>
<h2 id="Kafka-是如何实现高吞吐率的"><a href="#Kafka-是如何实现高吞吐率的" class="headerlink" title="Kafka 是如何实现高吞吐率的"></a>Kafka 是如何实现高吞吐率的</h2><p>Kafka是分布式消息系统，需要处理海量的消息，Kafka的设计是把所有的消息都写入速度低容量大的硬盘，以此来换取更强的存储能力，但实际上，使用硬盘并没有带来过多的性能损失。kafka主要使用了以下几个方式实现了超高的吞吐率：</p>
<ul>
<li><p>利用 Partition 实现并行处理 不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p>
</li>
<li><p>利用了现代操作系统分页存储 Page Cache 来利用内存提高 I&#x2F;O 效率</p>
</li>
<li><p>顺序写 kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p>
</li>
<li><p>Zero-copy 零拷技术减少拷贝次数</p>
</li>
<li><p>数据批量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络IO。因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。</p>
</li>
<li><p>Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。</p>
</li>
<li><p>数据压缩 Kafka还支持对消息集合进行压缩，Producer可以通过GZIP、Snappy、LZ4格式对消息集合进行压缩，数据压缩一般都是和批处理配套使用来作为优化手段的。压缩的好处就是减少传输的数据量，减轻对网络传输的压力 Producer压缩之后，在Consumer需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得</p>
</li>
<li><p>文件分段</p>
</li>
<li><p>批量发送</p>
</li>
</ul>
<h2 id="如何为Kafka集群选择合适的Topics-Partitions数量"><a href="#如何为Kafka集群选择合适的Topics-Partitions数量" class="headerlink" title="如何为Kafka集群选择合适的Topics&#x2F;Partitions数量"></a>如何为Kafka集群选择合适的Topics&#x2F;Partitions数量</h2><p>建一个只有1个分区的topic，然后测试这个topic的producer吞吐量和consumer吞吐量。假设它们的值分别是Tp和Tc，单位可以是MB&#x2F;s。然后假设总的目标吞吐量是Tt，那么分区数 &#x3D; Tt &#x2F; max(Tp, Tc)<br>Tp表示producer的吞吐量。测试producer通常是很容易的，因为它的逻辑非常简单，就是直接发送消息到Kafka就好了。Tc表示consumer的吞吐量。测试Tc通常与应用的关系更大， 因为Tc的值取决于你拿到消息之后执行什么操作，因此Tc的测试通常也要麻烦一些。<br>另外，Kafka并不能真正地做到线性扩展(其实任何系统都不能)，所以你在规划你的分区数的时候最好多规划一下，这样未来扩展时候也更加方便。</p>
<h2 id="Kafka-分区数可以增加或减少吗"><a href="#Kafka-分区数可以增加或减少吗" class="headerlink" title="Kafka 分区数可以增加或减少吗"></a>Kafka 分区数可以增加或减少吗</h2><p><strong>kafka支持分区数增加</strong></p>
<p>例如我们可以使用 <strong>bin&#x2F;kafka-topics.sh -alter –topic –topic topic-name –partitions 3</strong> 命令将原本分区数为1得topic-name设置为3。当主题中的消息包含有key时(即key不为null)，根据key来计算分区的行为就会有所影响。当topic-config的分区数为1时，不管消息的key为何值，消息都会发往这一个分区中；当分区数增加到3时，那么就会根据消息的key来计算分区号，原本发往分区0的消息现在有可能会发往分区1或者分区2中。如此还会影响既定消息的顺序，所以在增加分区数时一定要三思而后行。对于基于key计算的主题而言，建议在一开始就设置好分区数量，避免以后对其进行调整。</p>
<p><strong>Kafka 不支持减少分区数。</strong></p>
<p>按照Kafka现有的代码逻辑而言，此功能完全可以实现，不过也会使得代码的复杂度急剧增大。实现此功能需要考虑的因素很多，比如删除掉的分区中的消息该作何处理？如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留。直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于Spark、Flink这类需要消息时间戳(事件时间)的组件将会受到影响；如果分散插入到现有的分区中，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题、以及分区和副本的状态机切换问题都是不得不面对的。反观这个功能的收益点却是很低，如果真的需要实现此类的功能，完全可以重新创建一个分区数较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。</p>
<h2 id="kafka-follower如何与leader同步数据"><a href="#kafka-follower如何与leader同步数据" class="headerlink" title="kafka follower如何与leader同步数据"></a>kafka follower如何与leader同步数据</h2><p>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。</p>
<h2 id="Kafka生产者发送消息有哪些模式"><a href="#Kafka生产者发送消息有哪些模式" class="headerlink" title="Kafka生产者发送消息有哪些模式"></a>Kafka生产者发送消息有哪些模式</h2><h3 id="同步发送"><a href="#同步发送" class="headerlink" title="同步发送"></a>同步发送</h3><p>对于生产者的异步发送来说就是，我发送完当前消息后，并不需要你将当前消息的发送结果立马告诉我，而是可以随即进行下一条消息的发送。但是我会允许添加一个回调函数，接收你后续返回的发送结果。异步发送这块我们直接调用kafkaProducer的send方法即可实现异步发送。</p>
<h3 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h3><p>如果生产者需要使用同步发送的方式，只需要拿到 send 方法返回的future对象后，调用其 get() 方法即可。此时如果消息还未发送到broker中，get方法会被阻塞，等到 broker 返回消息发送结果后会跳出当前方法并将结果返回。</p>
<h2 id="Kafka发送消息的分区策略有哪些"><a href="#Kafka发送消息的分区策略有哪些" class="headerlink" title="Kafka发送消息的分区策略有哪些"></a>Kafka发送消息的分区策略有哪些</h2><p>所谓分区写入策略，即是生产者将数据写入到kafka主题后，kafka如何将数据分配到不同分区中的策略。</p>
<p>常见的有三种策略，轮询策略，随机策略，和按键保存策略。其中轮询策略是默认的分区策略，而随机策略则是较老版本的分区策略，不过由于其分配的均衡性不如轮询策略，故而后来改成了轮询策略为默认策略。</p>
<h2 id="Kafka如何增强消费者的消费能力"><a href="#Kafka如何增强消费者的消费能力" class="headerlink" title="Kafka如何增强消费者的消费能力"></a>Kafka如何增强消费者的消费能力</h2><p>1、如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数&#x3D;&#x3D;分区数。两者缺一不可。</p>
<p>2、如果是下游的数据处理不及时：则提高每批次拉取的数量。批次拉取数据过少（拉取数据&#x2F;处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</p>
<p>3、优化消费者的处理逻辑，提高处理效率</p>
<h2 id="为什么Kafka不支持读写分离"><a href="#为什么Kafka不支持读写分离" class="headerlink" title="为什么Kafka不支持读写分离"></a>为什么Kafka不支持读写分离</h2><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。</p>
<p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p>
<ol>
<li>数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</li>
<li>延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</li>
</ol>
<h2 id="Kafka选举机制"><a href="#Kafka选举机制" class="headerlink" title="Kafka选举机制"></a>Kafka选举机制</h2><p>Kafka选举主要分为以下三种：</p>
<ol>
<li>控制器（Broker）选举机制</li>
<li>分区副本选举机制</li>
<li>消费组选举机制</li>
</ol>
<p><strong>控制器选举</strong></p>
<p>控制器是Kafka的核心组件，它的主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群包括所有分区与副本的状态。集群中任意一个Broker都能充当控制器的角色，但在运行过程中，只能有一个Broker成为控制器。集群中第一个启动的Broker会通过在Zookeeper中创建临时节点&#x2F;controller来让自己成为控制器，其他Broker启动时也会在zookeeper中创建临时节点，但是发现节点已经存在，所以它们会收到一个异常，意识到控制器已经存在，那么就会在Zookeeper中创建watch对象，便于它们收到控制器变更的通知。如果控制器与Zookeeper断开连接或异常退出，其他broker通过watch收到控制器变更的通知，就会尝试创建临时节点&#x2F;controller，如果有一个Broker创建成功，那么其他broker就会收到创建异常通知，代表控制器已经选举成功，其他Broker只需创建watch对象即可。</p>
<p>  <strong>控制器作用</strong></p>
<ol>
<li>主题管理：创建、删除Topic，以及增加Topic分区等操作都是由控制器执行。</li>
<li>分区重分配：执行Kafka的reassign脚本对Topic分区重分配的操作，也是由控制器实现。如果集群中有一个Broker异常退出，控制器会检查这个broker是否有分区的副本leader，如果有那么这个分区就需要一个新的leader，此时控制器就会去遍历其他副本，决定哪一个成为新的leader，同时更新分区的ISR集合。如果有一个Broker加入集群中，那么控制器就会通过Broker ID去判断新加入的Broker中是否含有现有分区的副本，如果有，就会从分区副本中去同步数据。</li>
<li>Preferred leader选举：因为在Kafka集群长时间运行中，broker的宕机或崩溃是不可避免的，leader就会发生转移，即使broker重新回来，也不会是leader了。在众多leader的转移过程中，就会产生leader不均衡现象，可能一小部分broker上有大量的leader，影响了整个集群的性能，所以就需要把leader调整回最初的broker上，这就需要Preferred leader选举。</li>
<li>集群成员管理：控制器能够监控新broker的增加，broker的主动关闭与被动宕机，进而做其他工作。这也是利用Zookeeper的ZNode模型和Watcher机制，控制器会监听Zookeeper中&#x2F;brokers&#x2F;ids下临时节点的变化。同时对broker中的leader节点进行调整。</li>
<li>元数据服务：控制器上保存了最全的集群元数据信息，其他所有broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</li>
</ol>
<p><strong>分区副本选举机制</strong></p>
<p>发生副本选举的情况：</p>
<ol>
<li>创建主题</li>
<li>增加分区</li>
<li>分区下线（分区中原先的leader副本下线，此时分区需要选举一个新的leader上线来对外提供服务）</li>
<li>分区重分配</li>
</ol>
<p>分区leader副本的选举由Kafka控制器负责具体实施。主要过程如下：</p>
<ol>
<li>从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合。</li>
<li>调用配置的分区选择算法选择分区的leader。</li>
</ol>
<p>分区副本分为ISR（同步副本）和OSR（非同步副本），当leader发生故障时，只有“同步副本”才可以被选举为leader。选举时按照集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。同时kafka支持OSR（非同步副本）也参加选举，Kafka broker端提供了一个参数unclean.leader.election.enable，用于控制是否允许非同步副本参与leader选举；如果开启，则当 ISR为空时就会从这些副本中选举新的leader，这个过程称为 Unclean leader选举。可以根据实际的业务场景选择是否开启Unclean leader选举。开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。一般建议是关闭Unclean leader选举，因为通常数据的一致性要比可用性重要。</p>
<p><strong>消费组（Consumer Group）选主</strong></p>
<p>在Kafka的消费端，会有一个消费者协调器以及消费组，组协调器（Group Coordinator）需要为消费组内的消费者选举出一个消费组的leader。如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader，如果某一个时刻leader消费者由于某些原因退出了消费组，那么就会重新选举leader，选举源码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">private val members = new mutable.HashMap[String, MemberMetadata]</span><br><span class="line">leaderId = members.keys.headOption</span><br></pre></td></tr></table></figure>

<p>在组协调器中消费者的信息是以HashMap的形式存储的，其中key为消费者的member_id，而value是消费者相关的元数据信息。而leader的取值为HashMap中的第一个键值对的key（这种选举方式等同于随机）。</p>
<p>消费组的Leader和Coordinator没有关联。消费组的leader负责Rebalance过程中消费分配方案的制定。</p>
<h2 id="Kafka-Controller脑裂问题"><a href="#Kafka-Controller脑裂问题" class="headerlink" title="Kafka Controller脑裂问题"></a>Kafka Controller脑裂问题</h2><p>controller挂掉后，Kafka集群会重新选举一个新的controller。这里面存在一个问题，很难确定之前的controller节点是挂掉还是只是短暂性的故障。如果之前挂掉的controller又正常了，他并不知道自己已经被取代了，那么此时集群中会出现两台controller。</p>
<p>其实这种情况是很容易发生。比如，某个controller由于GC而被认为已经挂掉，并选择了一个新的controller。在GC的情况下，在最初的controller眼中，并没有改变任何东西，该Broker甚至不知道它已经暂停了。因此，它将继续充当当前controller，这是分布式系统中的常见情况，称为脑裂。</p>
<p>假如，处于活跃状态的controller进入了长时间的GC暂停。它的ZooKeeper会话过期了，之前注册的&#x2F;controller节点被删除。集群中其他Broker会收到zookeeper的这一通知。<img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c1f27036-7dc5-11ec-8893-fa163eb4f6be.png" alt="img">由于集群中必须存在一个controller Broker，所以现在每个Broker都试图尝试成为新的controller。假设Broker 2速度比较快，成为了最新的controller Broker。此时，每个Broker会收到Broker2成为新的controller的通知，由于Broker3正在进行”stop the world”的GC，可能不会收到Broker2成为最新的controller的通知。<img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c211aae6-7dc5-11ec-8893-fa163eb4f6be.png" alt="img">等到Broker3的GC完成之后，仍会认为自己是集群的controller，在Broker3的眼中好像什么都没有发生一样。<img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c232a7fa-7dc5-11ec-8893-fa163eb4f6be.png" alt="img">现在，集群中出现了两个controller，它们可能一起发出具有冲突的命令，就会出现脑裂的现象。如果对这种情况不加以处理，可能会导致严重的不一致。所以需要一种方法来区分谁是集群当前最新的Controller。</p>
<p>Kafka是通过使用epoch number（纪元编号，也称为隔离令牌）来完成的。epoch number只是单调递增的数字，第一次选出Controller时，epoch number值为1，如果再次选出新的Controller，则epoch number将为2，依次单调递增。</p>
<p>每个新选出的controller通过Zookeeper 的条件递增操作获得一个全新的、数值更大的epoch number 。其他Broker 在知道当前epoch number 后，如果收到由controller发出的包含较旧(较小)epoch number的消息，就会忽略它们，即Broker根据最大的epoch number来区分当前最新的controller。<img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2536ce2-7dc5-11ec-8893-fa163eb4f6be.png" alt="img">上图，Broker3向Broker1发出命令:让Broker1上的某个分区副本成为leader，该消息的epoch number值为1。于此同时，Broker2也向Broker1发送了相同的命令，不同的是，该消息的epoch number值为2，此时Broker1只听从Broker2的命令(由于其epoch number较大)，会忽略Broker3的命令，从而避免脑裂的发生。</p>
<h2 id="谈谈你对Kafka生产者幂等性的了解"><a href="#谈谈你对Kafka生产者幂等性的了解" class="headerlink" title="谈谈你对Kafka生产者幂等性的了解"></a>谈谈你对Kafka生产者幂等性的了解</h2><blockquote>
<p>Kafka精确一次性（Exactly-once）保障之一</p>
</blockquote>
<p>生产者幂等性主要避免生产者数据重复提交至Kafka broker中并落盘。在正常情况下，Producer向Broker发送消息，Broker将消息追加写到对应的流（即某一Topic的某一Partition）中并落盘，并向Producer返回ACK信号，表示确认收到。但是Producer和Broker之间的通信总有可能出现异常，如果消息已经写入，但ACK在半途丢失了，Producer就会进行retry操作再次发送该消息，造成重复写入。</p>
<p>为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。</p>
<ul>
<li>PID。每个新的Producer在初始化的时候会被分配一个唯一的PID，这个PID对用户是不可见的。</li>
<li>Sequence Numbler。对于每个PID，该Producer发送数据的每个都对应一个从0开始单调递增的Sequence Number</li>
<li>Broker端在缓存中保存了这seq number,对于接收的每条消息,如果其序号比Broker缓存中序号大于1则接受它,否则将其丢弃,这样就可以实现了消息重复提交了.但是只能保证单个Producer对于同一个的Exactly Once语义</li>
</ul>
<p><img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2844f10-7dc5-11ec-8893-fa163eb4f6be.png" alt="img"><img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220125_c2a15132-7dc5-11ec-8893-fa163eb4f6be.png" alt="img"></p>
<p>Producer使用幂等性的示例非常简单,与正常情况下Producer使用相比变化不大,只需要 把Producer的配置enable.idempotence设置为true即可,如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, &quot;true&quot;);</span><br><span class="line">//当enable.idempotence为true时acks默认为 all</span><br><span class="line">// props.put(&quot;acks&quot;, &quot;all&quot;);</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">KafkaProducer producer = new KafkaProducer(props);</span><br><span class="line">producer.send(new ProducerRecord(topic, &quot;test&quot;);</span><br></pre></td></tr></table></figure>

<p>Prodcuer 幂等性对外保留的接口非常简单，其底层的实现对上层应用做了很好的封装，应用层并不需要去关心具体的实现细节，对用户非常友好</p>
<p>Kafka的幂等性实现了对于单个Producer会话、单个TopicPartition级别的不重不漏，也就是最细粒度的保证。如果Producer重启（PID发生变化），或者写入是跨Topic、跨Partition的，单纯的幂等性就会失效，需要更高级别的事务性来解决了。当然事务性的原理更加复杂</p>
<h2 id="谈谈你对-Kafka事务的了解"><a href="#谈谈你对-Kafka事务的了解" class="headerlink" title="谈谈你对 Kafka事务的了解"></a>谈谈你对 Kafka事务的了解</h2><p>幂等性可以保证单个Producer会话、单个TopicPartition、单个会话session的不重不漏，如果Producer重启，或者是写入跨Topic、跨Partition的消息，幂等性无法保证。此时需要用到Kafka事务。Kafka 的事务处理，主要是允许应用可以把消费和生产的 batch 处理（涉及多个 Partition）在一个原子单元内完成，操作要么全部完成、要么全部失败。为了实现这种机制，我们需要应用能提供一个唯一 id，即使故障恢复后也不会改变，这个 id 就是 TransactionnalId（也叫 txn.id），txn.id 可以跟内部的 PID 1:1 分配，它们不同的是 txn.id 是用户提供的，而 PID 是 Producer 内部自动生成的（并且故障恢复后这个 PID 会变化），有了 txn.id 这个机制，就可以实现多 partition、跨会话的 EOS 语义。当用户使用 Kafka 的事务性时，Kafka 可以做到的保证：</p>
<ol>
<li>跨会话的幂等性写入：即使中间故障，恢复后依然可以保持幂等性；</li>
<li>跨会话的事务恢复：如果一个应用实例挂了，启动的下一个实例依然可以保证上一个事务完成（commit 或者 abort）；</li>
<li>跨多个 Topic-Partition 的幂等性写入，Kafka 可以保证跨多个 Topic-Partition 的数据要么全部写入成功，要么全部失败，不会出现中间状态。</li>
</ol>
<p><strong>事务性示例</strong></p>
<p>Kafka 事务性的使用方法也非常简单，用户只需要在 Producer 的配置中配置 transactional.id，通过 initTransactions() 初始化事务状态信息，再通过 beginTransaction() 标识一个事务的开始，然后通过 commitTransaction() 或 abortTransaction() 对事务进行 commit 或 abort，示例如下所示：生产者：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">props.put(&quot;client.id&quot;, &quot;ProducerTranscationnalExample&quot;);</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;transactional.id&quot;, &quot;test-transactional&quot;);</span><br><span class="line">props.put(&quot;acks&quot;, &quot;all&quot;);</span><br><span class="line">KafkaProducer producer = new KafkaProducer(props);</span><br><span class="line">producer.initTransactions();</span><br><span class="line">try &#123;</span><br><span class="line">    String msg = &quot;matt test&quot;;</span><br><span class="line">    producer.beginTransaction();</span><br><span class="line">    producer.send(new ProducerRecord(topic, &quot;0&quot;, msg.toString()));</span><br><span class="line">    producer.send(new ProducerRecord(topic, &quot;1&quot;, msg.toString()));</span><br><span class="line">    producer.send(new ProducerRecord(topic, &quot;2&quot;, msg.toString()));</span><br><span class="line">    producer.commitTransaction();</span><br><span class="line">&#125; catch (ProducerFencedException e1) &#123;</span><br><span class="line">    e1.printStackTrace();</span><br><span class="line">    producer.close();</span><br><span class="line">&#125; catch (KafkaException e2) &#123;</span><br><span class="line">    e2.printStackTrace();</span><br><span class="line">    producer.abortTransaction();</span><br><span class="line">&#125;</span><br><span class="line">producer.close();</span><br></pre></td></tr></table></figure>

<p>消费者：消费者应该设置提交事务的隔离级别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG,&quot;read_committed&quot;);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Kafka中只有两种事务隔离级别：readcommitted、readuncommitted 设置为readcommitted时候是生产者事务已提交的数据才能读取到。在执行 commitTransaction() 或 abortTransaction() 方法前，设置为“readcommitted”的消费端应用是消费不到这些消息的，不过在 KafkaConsumer 内部会缓存这些消息，直到生产者执行 commitTransaction() 方法之后它才能将这些消息推送给消费端应用。同时KafkaConsumer会根据分区对数据进行整合，推送时按照分区顺序进行推送。而不是按照数据发送顺序。反之，如果生产者执行了 abortTransaction() 方法，那么 KafkaConsumer 会将这些缓存的消息丢弃而不推送给消费端应用。设置为read_uncommitted时候可以读取到未提交的数据(报错终止前的数据)</p>
</blockquote>
<h2 id="消息如何分发"><a href="#消息如何分发" class="headerlink" title="消息如何分发"></a>消息如何分发</h2><p>若该队列⾄少有⼀个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给⼀个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。</p>
<h2 id="Consumer-commit机制是什么"><a href="#Consumer-commit机制是什么" class="headerlink" title="Consumer commit机制是什么"></a>Consumer commit机制是什么</h2><p>偏移量的确认，在push模式下是通过ack来确定，如果失败进去重试队列，在pull模式下可以自动确认也可手动确认，但是异常就没办法进入重试队列</p>
<h2 id="RocketMQ实现原理"><a href="#RocketMQ实现原理" class="headerlink" title="RocketMQ实现原理"></a>RocketMQ实现原理</h2><p>RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成，它的架构原理是这样的：</p>
<ol>
<li>Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳</li>
<li>Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息</li>
<li>Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费</li>
</ol>
<p><img src="/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/RocketMQ.jpg"></p>
<h2 id="为什么RocketMQ不使用Zookeeper作为注册中心呢？"><a href="#为什么RocketMQ不使用Zookeeper作为注册中心呢？" class="headerlink" title="为什么RocketMQ不使用Zookeeper作为注册中心呢？"></a>为什么RocketMQ不使用Zookeeper作为注册中心呢？</h2><p>我认为有以下几个点是不使用zookeeper的原因：</p>
<ol>
<li>根据CAP理论，同时最多只能满足两个点，而zookeeper满足的是CP，也就是说zookeeper并不能保证服务的可用性，zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。</li>
<li>基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而zookeeper的写是不可扩展的，而zookeeper要解决这个问题只能通过划分领域，划分多个zookeeper集群来解决，首先操作起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通的。</li>
<li>持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。</li>
<li>消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。</li>
</ol>
<h2 id="RocketMQ-Broker怎么保存数据"><a href="#RocketMQ-Broker怎么保存数据" class="headerlink" title="RocketMQ Broker怎么保存数据"></a>RocketMQ Broker怎么保存数据</h2><p>RocketMQ主要的存储文件包括commitlog文件、consumequeue文件、indexfile文件。</p>
<p>Broker在收到消息之后，会把消息保存到commitlog的文件当中，而同时在分布式的存储当中，每个broker都会保存一部分topic的数据，同时，每个topic对应的messagequeue下都会生成consumequeue文件用于保存commitlog的物理位置偏移量offset，indexfile中会保存key和offset的对应关系。</p>
<h2 id="RocketMQ中Master和Slave间怎么同步数据"><a href="#RocketMQ中Master和Slave间怎么同步数据" class="headerlink" title="RocketMQ中Master和Slave间怎么同步数据"></a>RocketMQ中Master和Slave间怎么同步数据</h2><p>消息在master和slave之间的同步是根据raft协议来进行的：</p>
<ol>
<li>在broker收到消息后，会被标记为uncommitted状态</li>
<li>然后会把消息发送给所有的slave</li>
<li>slave在收到消息之后返回ack响应给master</li>
<li>master在收到超过半数的ack之后，把消息标记为committed</li>
<li>发送committed消息给所有slave，slave也修改状态为committed</li>
</ol>
<h2 id="RocketMQ为什么速度快"><a href="#RocketMQ为什么速度快" class="headerlink" title="RocketMQ为什么速度快"></a>RocketMQ为什么速度快</h2><p>是因为使用了顺序存储、Page Cache和异步刷盘。</p>
<ol>
<li>我们在写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多</li>
<li>写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache</li>
<li>最后由操作系统异步将缓存中的数据刷到磁盘</li>
</ol>
<h2 id="什么是事务、半事务消息？怎么实现的？"><a href="#什么是事务、半事务消息？怎么实现的？" class="headerlink" title="什么是事务、半事务消息？怎么实现的？"></a>什么是事务、半事务消息？怎么实现的？</h2><p>事务消息就是MQ提供的类似XA的分布式事务能力，通过事务消息可以达到分布式事务的最终一致性。</p>
<p>半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。</p>
<p>实现原理如下：</p>
<ol>
<li>生产者先发送一条半事务消息到MQ</li>
<li>MQ收到消息后返回ack确认</li>
<li>生产者开始执行本地事务</li>
<li>如果事务执行成功发送commit到MQ，失败发送rollback</li>
<li>如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查</li>
<li>生产者查询事务执行最终状态</li>
<li>根据查询事务状态再次提交二次确认</li>
</ol>
<p>最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。</p>
<p><img src="/2022/07/02/MessageQueue-%E9%9D%A2%E8%AF%95%E9%A2%98/RocketMQ_Transaction.jpg"></p>
<h2 id="RabbitMQ消息基于什么传输"><a href="#RabbitMQ消息基于什么传输" class="headerlink" title="RabbitMQ消息基于什么传输"></a>RabbitMQ消息基于什么传输</h2><p>RabbitMQ使⽤信道的⽅式来传输数据。信道是建⽴在真实的TCP连接内的虚拟连接，且每条</p>
<p>TCP连接上的信道数量没有限制。</p>
<ol>
<li>RabbitMQ采⽤类似NIO（Non-blocking I&#x2F;O）做法，选择TCP连接复⽤，不仅可以减少性能开销，同时也便于管理。</li>
<li>每个线程把持⼀个信道，所以信道服⽤了Connection的TCP连接。同时RabbitMQ可以确保每个线程的私密性，就像拥有独立的连接一样。</li>
</ol>
<h2 id="RabbitMQ消息怎么路由"><a href="#RabbitMQ消息怎么路由" class="headerlink" title="RabbitMQ消息怎么路由"></a>RabbitMQ消息怎么路由</h2><p>从概念上来说，消息路由必须有三部分：交换器、路由、绑定。⽣产者把消息发布到交换器上；绑定决定了消息如何从交换器路由到特定的队列；消息最终到达队列，并被消费者接收。</p>
<ol>
<li>消息发布到交换器时，消息将拥有⼀个路由键（routing key），在消息创建时设定。</li>
<li>通过队列路由键，可以把队列绑定到交换器上。</li>
<li>消息到达交换器后，RabbitMQ会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）。</li>
<li>如果能够匹配到队列，则消息会投递到相应队列中；如果不能匹配到任何队列，消息将进⼊ “⿊洞”。</li>
</ol>
<h2 id="RabbitMQ-的高可用性"><a href="#RabbitMQ-的高可用性" class="headerlink" title="RabbitMQ 的高可用性"></a>RabbitMQ 的高可用性</h2><p>在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>
<h2 id="RocketMQ-的高可用性"><a href="#RocketMQ-的高可用性" class="headerlink" title="RocketMQ 的高可用性"></a>RocketMQ 的高可用性</h2><ul>
<li>多master 模式</li>
<li>多master多slave异步复制模式</li>
<li>多 master多slave同步双写模式</li>
</ul>
<p>多master多slave模式通信过程如下</p>
<p>Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。</p>
<h2 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h2><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。</p>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><ul>
<li>一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</li>
<li>写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li>
</ul>
<h2 id="消息积压"><a href="#消息积压" class="headerlink" title="消息积压"></a>消息积压</h2><ul>
<li>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。</li>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li>
<li>等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。</li>
</ul>
<h2 id="RabbitMQ设置过期时间，部分消息丢失"><a href="#RabbitMQ设置过期时间，部分消息丢失" class="headerlink" title="RabbitMQ设置过期时间，部分消息丢失"></a>RabbitMQ设置过期时间，部分消息丢失</h2><p>批量重导</p>
<h2 id="MQ磁盘写满"><a href="#MQ磁盘写满" class="headerlink" title="MQ磁盘写满"></a>MQ磁盘写满</h2><p>代表已经积压过度。添加新消费者，或记录SEEK 号后，接入新程序消费后丢弃，空闲时刻重新SEEK消费</p>
<h2 id="如何设计MQ"><a href="#如何设计MQ" class="headerlink" title="如何设计MQ"></a>如何设计MQ</h2><ul>
<li>首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</li>
<li>其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。</li>
<li>其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</li>
<li>能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。</li>
</ul>
<h2 id="Redis做消息队列与其他消息队列相比有什么不同"><a href="#Redis做消息队列与其他消息队列相比有什么不同" class="headerlink" title="Redis做消息队列与其他消息队列相比有什么不同"></a>Redis做消息队列与其他消息队列相比有什么不同</h2><h3 id="Redis作为消息队列"><a href="#Redis作为消息队列" class="headerlink" title="Redis作为消息队列"></a>Redis作为消息队列</h3><ul>
<li>如果你的需求是快产快消的即时消费场景，并且生产的消息立即被消费者消费掉。</li>
<li>如果速度是你十分看重的，比如慢了一秒好几千万这种。</li>
<li>如果允许出现消息丢失的场景。</li>
<li>如果你不需要系统保存你发送过的消息。</li>
<li>如果需要处理的数据量并不是那么巨大。</li>
</ul>
<h3 id="其他消息队列"><a href="#其他消息队列" class="headerlink" title="其他消息队列"></a>其他消息队列</h3><ul>
<li>如果你想要稳定的消息队列。</li>
<li>如果你想要你发送过的消息可以保留一定的时间，并不是无迹可寻的时候。</li>
<li>如果你无法忍受数据的丢失。</li>
<li>如果速度不需要那么的快。</li>
<li>如果需要处理数据量巨大的时候。</li>
</ul>
<h3 id="应用场景分析"><a href="#应用场景分析" class="headerlink" title="应用场景分析"></a>应用场景分析</h3><p>Redis：轻量级，高并发，延迟敏感<br>即时数据分析、秒杀计数器、缓存等。</p>
<p>其他MQ：重量级，高并发，异步<br>批量数据异步处理、并行任务串行化，高负载任务的负载均衡等。</p>
<h6 id="来源"><a href="#来源" class="headerlink" title="来源:"></a>来源:</h6><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904094021189639">https://juejin.cn/post/6844904094021189639</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1757914">https://cloud.tencent.com/developer/article/1757914</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yangyongjie/p/14675119.html">https://www.cnblogs.com/yangyongjie/p/14675119.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/368773517">https://zhuanlan.zhihu.com/p/368773517</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15127589/2679155">https://blog.51cto.com/u_15127589/2679155</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/282993811">https://zhuanlan.zhihu.com/p/282993811</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/helios-fz/p/12119727.html">https://www.cnblogs.com/helios-fz/p/12119727.html</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6973662966331736101">https://juejin.cn/post/6973662966331736101</a></p>
<p><a target="_blank" rel="noopener" href="https://www.modb.pro/db/241781">【万字长文】Kafka最全知识点整理（建议收藏） - 墨天轮 (modb.pro)</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/02/JAVA%E9%9D%A2%E8%AF%95%E6%80%9D%E8%B7%AF/" rel="prev" title="JAVA面试思路">
      <i class="fa fa-chevron-left"></i> JAVA面试思路
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/02/MySQL-%E5%A0%86%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98/" rel="next" title="MySQL-堆排序问题">
      MySQL-堆排序问题 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8MQ"><span class="nav-number">1.</span> <span class="nav-text">为什么使用MQ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MQ%E9%80%89%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">MQ选型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E4%BC%9A%E4%B8%8D%E4%BC%9A%E4%B8%A2%E6%B6%88%E6%81%AF"><span class="nav-number">3.</span> <span class="nav-text">Kafka 会不会丢消息</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Producer%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">3.1.</span> <span class="nav-text">Producer丢失消息的情况</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0"><span class="nav-number">3.1.1.</span> <span class="nav-text">产生原因</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF"><span class="nav-number">3.1.2.</span> <span class="nav-text">解决思路</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Consumer%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">3.2.</span> <span class="nav-text">Consumer丢失消息的情况</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">产生原因</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">3.2.2.</span> <span class="nav-text">解决办法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">3.3.</span> <span class="nav-text">Broker丢失消息的情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="nav-number">4.</span> <span class="nav-text">重复消费</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0%EF%BC%9A"><span class="nav-number">4.1.</span> <span class="nav-text">产生原因：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">4.2.</span> <span class="nav-text">解决方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-consumer-%E6%98%AF%E6%8E%A8%E8%BF%98%E6%98%AF%E6%8B%89%EF%BC%9F"><span class="nav-number">5.</span> <span class="nav-text">Kafka consumer 是推还是拉？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84"><span class="nav-number">6.</span> <span class="nav-text">Kafka 的设计架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="nav-number">7.</span> <span class="nav-text">Kafka 分区的目的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7"><span class="nav-number">8.</span> <span class="nav-text">Kafka 是如何做到消息的有序性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISR%E3%80%81OSR%E3%80%81AR-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">9.</span> <span class="nav-text">ISR、OSR、AR 是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86"><span class="nav-number">10.</span> <span class="nav-text">Kafka 数据一致性原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E5%88%86%E5%8C%BA%E6%B6%88%E6%81%AF"><span class="nav-number">11.</span> <span class="nav-text">Kafka 消费者是否可以消费指定分区消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E7%9A%84%E5%86%8D%E5%9D%87%E8%A1%A1"><span class="nav-number">12.</span> <span class="nav-text">Kafka 的再均衡</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-%E7%BB%B4%E6%8A%A4%E6%B6%88%E8%B4%B9%E7%8A%B6%E6%80%81%E8%B7%9F%E8%B8%AA%E7%9A%84%E6%96%B9%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88"><span class="nav-number">13.</span> <span class="nav-text">kafka 维护消费状态跟踪的方法有什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5"><span class="nav-number">14.</span> <span class="nav-text">Kafka主从同步</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Zookeeper-%E5%AF%B9%E4%BA%8E-Kafka-%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">15.</span> <span class="nav-text">Zookeeper 对于 Kafka 的作用是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9A%E4%B9%89%E6%9C%89%E5%93%AA%E4%B8%89%E7%A7%8D"><span class="nav-number">16.</span> <span class="nav-text">Kafka数据传输的事务定义有哪三种</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E8%BF%98%E5%AD%98%E6%B4%BB%E6%9D%A1%E4%BB%B6"><span class="nav-number">17.</span> <span class="nav-text">Kafka 判断一个节点是否还存活条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E4%B8%8E%E4%BC%A0%E7%BB%9F-MQ-%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="nav-number">18.</span> <span class="nav-text">Kafka 与传统 MQ 消息系统之间有什么区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%95%85%E9%9A%9C%EF%BC%8C%E5%87%BA%E7%8E%B0%E6%B4%BB%E9%94%81%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="nav-number">19.</span> <span class="nav-text">消费者故障，出现活锁问题如何解决</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E6%B6%88%E8%B4%B9%E7%9A%84%E4%BD%8D%E7%BD%AE"><span class="nav-number">20.</span> <span class="nav-text">Kafka如何控制消费的位置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9C%BA%E5%88%B6%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">21.</span> <span class="nav-text">Kafka 的高可用机制是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E7%8E%87%E7%9A%84"><span class="nav-number">22.</span> <span class="nav-text">Kafka 是如何实现高吞吐率的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%B8%BAKafka%E9%9B%86%E7%BE%A4%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84Topics-Partitions%E6%95%B0%E9%87%8F"><span class="nav-number">23.</span> <span class="nav-text">如何为Kafka集群选择合适的Topics&#x2F;Partitions数量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%88%86%E5%8C%BA%E6%95%B0%E5%8F%AF%E4%BB%A5%E5%A2%9E%E5%8A%A0%E6%88%96%E5%87%8F%E5%B0%91%E5%90%97"><span class="nav-number">24.</span> <span class="nav-text">Kafka 分区数可以增加或减少吗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-follower%E5%A6%82%E4%BD%95%E4%B8%8Eleader%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">25.</span> <span class="nav-text">kafka follower如何与leader同步数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E6%9C%89%E5%93%AA%E4%BA%9B%E6%A8%A1%E5%BC%8F"><span class="nav-number">26.</span> <span class="nav-text">Kafka生产者发送消息有哪些模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">26.1.</span> <span class="nav-text">同步发送</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">26.2.</span> <span class="nav-text">异步发送</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="nav-number">27.</span> <span class="nav-text">Kafka发送消息的分区策略有哪些</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E5%A6%82%E4%BD%95%E5%A2%9E%E5%BC%BA%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B"><span class="nav-number">28.</span> <span class="nav-text">Kafka如何增强消费者的消费能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88Kafka%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB"><span class="nav-number">29.</span> <span class="nav-text">为什么Kafka不支持读写分离</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6"><span class="nav-number">30.</span> <span class="nav-text">Kafka选举机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Controller%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98"><span class="nav-number">31.</span> <span class="nav-text">Kafka Controller脑裂问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B0%88%E8%B0%88%E4%BD%A0%E5%AF%B9Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7%E7%9A%84%E4%BA%86%E8%A7%A3"><span class="nav-number">32.</span> <span class="nav-text">谈谈你对Kafka生产者幂等性的了解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B0%88%E8%B0%88%E4%BD%A0%E5%AF%B9-Kafka%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%BA%86%E8%A7%A3"><span class="nav-number">33.</span> <span class="nav-text">谈谈你对 Kafka事务的了解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E5%A6%82%E4%BD%95%E5%88%86%E5%8F%91"><span class="nav-number">34.</span> <span class="nav-text">消息如何分发</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Consumer-commit%E6%9C%BA%E5%88%B6%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">35.</span> <span class="nav-text">Consumer commit机制是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RocketMQ%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">36.</span> <span class="nav-text">RocketMQ实现原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88RocketMQ%E4%B8%8D%E4%BD%BF%E7%94%A8Zookeeper%E4%BD%9C%E4%B8%BA%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%91%A2%EF%BC%9F"><span class="nav-number">37.</span> <span class="nav-text">为什么RocketMQ不使用Zookeeper作为注册中心呢？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RocketMQ-Broker%E6%80%8E%E4%B9%88%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE"><span class="nav-number">38.</span> <span class="nav-text">RocketMQ Broker怎么保存数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RocketMQ%E4%B8%ADMaster%E5%92%8CSlave%E9%97%B4%E6%80%8E%E4%B9%88%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">39.</span> <span class="nav-text">RocketMQ中Master和Slave间怎么同步数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RocketMQ%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%9F%E5%BA%A6%E5%BF%AB"><span class="nav-number">40.</span> <span class="nav-text">RocketMQ为什么速度快</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%8B%E5%8A%A1%E3%80%81%E5%8D%8A%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%EF%BC%9F%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="nav-number">41.</span> <span class="nav-text">什么是事务、半事务消息？怎么实现的？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RabbitMQ%E6%B6%88%E6%81%AF%E5%9F%BA%E4%BA%8E%E4%BB%80%E4%B9%88%E4%BC%A0%E8%BE%93"><span class="nav-number">42.</span> <span class="nav-text">RabbitMQ消息基于什么传输</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RabbitMQ%E6%B6%88%E6%81%AF%E6%80%8E%E4%B9%88%E8%B7%AF%E7%94%B1"><span class="nav-number">43.</span> <span class="nav-text">RabbitMQ消息怎么路由</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RabbitMQ-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-number">44.</span> <span class="nav-text">RabbitMQ 的高可用性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RocketMQ-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-number">45.</span> <span class="nav-text">RocketMQ 的高可用性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9"><span class="nav-number">46.</span> <span class="nav-text">顺序消费</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RabbitMQ"><span class="nav-number">46.1.</span> <span class="nav-text">RabbitMQ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka"><span class="nav-number">46.2.</span> <span class="nav-text">Kafka</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B"><span class="nav-number">47.</span> <span class="nav-text">消息积压</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RabbitMQ%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%EF%BC%8C%E9%83%A8%E5%88%86%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="nav-number">48.</span> <span class="nav-text">RabbitMQ设置过期时间，部分消息丢失</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MQ%E7%A3%81%E7%9B%98%E5%86%99%E6%BB%A1"><span class="nav-number">49.</span> <span class="nav-text">MQ磁盘写满</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1MQ"><span class="nav-number">50.</span> <span class="nav-text">如何设计MQ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis%E5%81%9A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%8E%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9B%B8%E6%AF%94%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C"><span class="nav-number">51.</span> <span class="nav-text">Redis做消息队列与其他消息队列相比有什么不同</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E4%BD%9C%E4%B8%BA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="nav-number">51.1.</span> <span class="nav-text">Redis作为消息队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="nav-number">51.2.</span> <span class="nav-text">其他消息队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90"><span class="nav-number">51.3.</span> <span class="nav-text">应用场景分析</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%9D%A5%E6%BA%90"><span class="nav-number">51.3.0.0.1.</span> <span class="nav-text">来源:</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">swzxsyh</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">208</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/swzxsyh" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;swzxsyh" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/swzxsyh" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;swzxsyh" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">swzxsyh</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '713a28a3ad93f2aa2323',
      clientSecret: '39dc40bb09b422ca4c99a748b5984a4d205e91be',
      repo        : 'swzxsyh.github.io',
      owner       : 'swzxsyh',
      admin       : ['swzxsyh'],
      id          : 'ff1eb98090d1458615727d4793e74407',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
